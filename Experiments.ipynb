{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import random\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.optimize import fsolve\n",
    "from multiprocessing import Pool\n",
    "from collections import ChainMap\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given the number of pods K, it returns the list of nodes indexed as [server,edge,aggregation,core] \n",
    "#and the list of links as [[indexSourceNode,indexTargetNode]]\n",
    "####################################################################################################\n",
    "#NB: in python 3 int/int yields float. In order to avoid problems with idexes \n",
    "#(which need to be integers), use int//int to produce int in output (it actually performs floor(a/b)) \n",
    "#####################################################################################################\n",
    "def getFatTree(K):\n",
    "    N_core = (K//2)**2\n",
    "    N_aggr = (K**2)//2\n",
    "    N_edge = N_aggr\n",
    "    N_serv = N_edge * K//2\n",
    "    N_tot = N_core + N_aggr + N_edge + N_serv\n",
    "    \n",
    "    serv_nodes = np.arange(N_serv)\n",
    "    edge_nodes = N_serv + np.arange(N_edge)\n",
    "    aggr_nodes = N_serv + N_edge + np.arange(N_aggr)\n",
    "    core_nodes = N_serv + N_edge + N_aggr + np.arange(N_core)\n",
    "\n",
    "    Adj =np.matrix(np.zeros((N_tot,N_tot)))\n",
    "    n_core_connected = np.zeros(N_aggr)\n",
    "    \n",
    "    #aggregation to edge\n",
    "    for k in range(K):#% k-th pod\n",
    "        a=N_serv+N_edge+k*K//2#starting index aggregation nodes\n",
    "        b=N_serv+k*K//2#starting index edge nodes\n",
    "        Adj[a:a+K//2,b:b+K//2] = np.ones((K//2,K//2))\n",
    "        \n",
    "    #edge to servers\n",
    "    for e in range(N_edge):\n",
    "        a=N_serv+e#starting index edge nodes\n",
    "        b=e*K//2#starting index connected servers\n",
    "        Adj[a,b:b+K//2] = 1\n",
    "        \n",
    "    #core to aggregation    \n",
    "    for c in range(N_core):\n",
    "        a= N_serv + N_edge + N_aggr+c#index of core node\n",
    "        for k in range(K): # pod number\n",
    "            b=N_serv + N_edge+k*K//2#starting index of pod\n",
    "            ind_aggr = np.where(n_core_connected[k*K//2:(k+1)*(K//2)]<K//2)[0][0]#index of the aggregation node inside the pod\n",
    "            Adj[a,b+ind_aggr] = 1;\n",
    "            n_core_connected[k*K//2+ind_aggr] = n_core_connected[k*K//2+ind_aggr]+1;#update the number of connection per aggregation node\n",
    "\n",
    "    Adj = Adj + Adj.T\n",
    "    Adj[Adj>1] = 1\n",
    "    L = np.where(Adj==1)\n",
    "    links=np.array([[L[1][i],L[0][i]] for i in range(len(L[0]))]) \n",
    "    return links,serv_nodes,edge_nodes,aggr_nodes,core_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_band(C,paths):\n",
    "    '''Computes the residual bandwidth for all input paths given the residual bandwidth'''\n",
    "    \n",
    "    res_band =[]\n",
    "    for ii in range(len(paths)):\n",
    "        vec = []\n",
    "        for tt in paths[ii]:\n",
    "            vec.append(C[tt])\n",
    "        res_band.append(np.min(vec))\n",
    "\n",
    "    return res_band\n",
    "\n",
    "def intersect(a, b):\n",
    "    return list(set(a) & set(b))\n",
    "\n",
    "\n",
    "def max_min_allocation(C,paths, debug_flag=0):\n",
    "    '''Computes the max-min allocation in a capacitated graph G for all input paths'''\n",
    "    \n",
    "    C = np.array(C, dtype=float)\n",
    "    paths = pd.Series(paths)\n",
    "    \n",
    "    # check input consistency\n",
    "    if (np.sum(C<0)>0):\n",
    "        raise ValueError('Capacity must be nonnegative.')\n",
    "    \n",
    "    # Initialization\n",
    "    max_min_rates = np.zeros(len(paths))\n",
    "\n",
    "    N = len(C) # n. edges\n",
    "    n_paths_per_edge = np.zeros(N, dtype=int) # n_paths_per_edge[i] = n. of paths passing through edge i\n",
    "    for ii,val in enumerate(paths):\n",
    "        for tt in val:\n",
    "            n_paths_per_edge[tt] += 1\n",
    "\n",
    "    paths_not_bottlenecked = [True for ii in range(len(paths))] #np.ones([1,len(paths)],dtype=bool)\n",
    "    \n",
    "    # Max-min algorithm\n",
    "    it = 0;\n",
    "    \n",
    "    if(debug_flag):\n",
    "        print(\"iteration \" + str(it))\n",
    "        print(\"max_min_rates = \" + str(max_min_rates))\n",
    "        print(\"paths_not_bottlenecked = \" + str(paths_not_bottlenecked))\n",
    "        print(\"available bandwidth C = \" + str(C))\n",
    "        print(\"n_paths_per_edge = \" + str(n_paths_per_edge) + \"\\n\")\n",
    "       \n",
    "    \n",
    "    while np.sum(paths_not_bottlenecked)>0:\n",
    "        \n",
    "        vec = np.array([float(\"Inf\") for ii in range(len(C))])\n",
    "        bool_vec = (n_paths_per_edge>0)\n",
    "        vec[bool_vec] = C[bool_vec] / n_paths_per_edge[bool_vec]\n",
    "        \n",
    "        bottleneck_flow = np.nanmin(vec) # maximum amount of flow increment for not bottlenecked flows\n",
    "        bottleneck_links = np.where(vec==bottleneck_flow)[0] # links with no capacity left\n",
    "        for ii in range(len(paths_not_bottlenecked)):\n",
    "                if paths_not_bottlenecked[ii]:\n",
    "                    max_min_rates[ii] += bottleneck_flow\n",
    "        \n",
    "        for ii, val in paths[paths_not_bottlenecked].iteritems():\n",
    "            C[val] -= bottleneck_flow\n",
    "            if intersect(val,bottleneck_links):\n",
    "                paths_not_bottlenecked[ii] = False\n",
    "                for tt in val:\n",
    "                    n_paths_per_edge[tt] -= 1\n",
    "        # import pdb; pdb.set_trace() # DEBUG\n",
    "        it += 1\n",
    "        \n",
    "        if(debug_flag):\n",
    "            print(\"iteration \" + str(it))\n",
    "            print(\"max_min_rates = \" + str(max_min_rates))\n",
    "            print(\"paths_not_bottlenecked = \" + str(paths_not_bottlenecked))\n",
    "            print(\"available bandwidth C = \" + str(C))\n",
    "            print(\"n_paths_per_edge = \" + str(n_paths_per_edge) + \"\\n\")\n",
    "    \n",
    "    \n",
    "    return max_min_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computes all the shortest paths from all nodes in serverNodesIndexes to all nodes in serverNodesIndexes\n",
    "#returns a dictionary ECMPs[(source,destination)]=[path_1,path_1,...,path_n]\n",
    "#path_i=[source, node_1,...,node_n,...destination]\n",
    "#since the topology is symmetric, it computes only the paths from a to b: those from b to a can be reconstructed\n",
    "def getAllECMPs(G,serverNodesIndexes):\n",
    "    ECMPs={}\n",
    "    for i in range(len(serverNodesIndexes)-1):\n",
    "        s=serverNodesIndexes[i]\n",
    "        for j in range(i+1,len(serverNodesIndexes)):\n",
    "            d=serverNodesIndexes[j]\n",
    "            ECMPs[(s,d)]=list(nx.all_shortest_paths(G,s,d))\n",
    "    return ECMPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic subroutine in the parallel computation\n",
    "#only difference: list of source and destination nodes are distinct\n",
    "def getAllECMPs_parallel_basicRoutine(G,sourcesIndexes,destinationsIndexes):\n",
    "    ECMPs={}\n",
    "    for i in range(len(sourcesIndexes)):\n",
    "        s=sourcesIndexes[i]\n",
    "        for j in range(len(destinationsIndexes)):\n",
    "            d=destinationsIndexes[j]\n",
    "            if d>s:\n",
    "                ECMPs[(s,d)]=list(nx.all_shortest_paths(G,s,d))\n",
    "    return ECMPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parallel version of getAllECMPs\n",
    "def getAllECMPs_parallel(G,serverNodesIndexes,n_jobs):\n",
    "    #calculate the indexes to split the calculation so that the job load in evenly distributed\n",
    "    fairIndexes=getFairIndexes(len(serverNodesIndexes),n_jobs)\n",
    "    #split the input in chunks\n",
    "    inputs=[[G,serverNodesIndexes[fairIndexes[i]:fairIndexes[i+1]],serverNodesIndexes] for i in range(len(fairIndexes)-1)]\n",
    "    inputs=[[G,serverNodesIndexes[:fairIndexes[0]],serverNodesIndexes]]+inputs+[[G,serverNodesIndexes[fairIndexes[-1]:],serverNodesIndexes]]\n",
    "    with Pool(n_jobs) as p:\n",
    "        ECMPs=p.starmap(getAllECMPs_parallel_basicRoutine,inputs)\n",
    "    #merge n_jobs dictionaries into a single one\n",
    "    ECMPs=dict(ChainMap(*ECMPs))\n",
    "    return ECMPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "P=getAllECMPs_parallel(G,servers,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the indexes to split the 'all shortest paths' calculation in n_jobs in a fair way \n",
    "def getFairIndexes(n_server_nodes,n_jobs):\n",
    "\n",
    "    def fairIndexes(X):\n",
    "        Y=[]\n",
    "        X=[0]+list(X)\n",
    "        for i in range(1,len(X)-1):\n",
    "            a=(n_server_nodes-X[i])*(X[i]-X[i-1])+.5*(X[i]-X[i-1])**2\n",
    "            b=(n_server_nodes-X[i+1])*(X[i+1]-X[i])+.5*(X[i+1]-X[i])**2\n",
    "            Y.append(float(a-b))\n",
    "        \n",
    "        a=(n_server_nodes-X[-1])*(X[-1]-X[-2])+.5*(X[-1]-X[-2])**2\n",
    "        b=.5*(n_server_nodes-X[-1])**2        \n",
    "        Y.append(float(a-b))\n",
    "        return tuple(Y)\n",
    "    X=[i*n_server_nodes//n_jobs for i in range(n_jobs)]\n",
    "    a=fsolve(fairIndexes,X)\n",
    "    return a.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given diGraph G. source node index and target node index, returns the ECMP path as sequnce of node Ids\n",
    "#This will be optimized by precomputing the shortest paths for each source-destination couple\n",
    "def ECMP(G,source,target):\n",
    "    paths=[p for p in nx.all_shortest_paths(G,source,target)]\n",
    "    i=random.randint(0,len(paths)-1)\n",
    "    return paths[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updates the currentRate parameter on each link affected by a maxMin routing\n",
    "#G is a diGraph, \n",
    "#C is a list of capacity of each link, ordered as given by list(G.edges())\n",
    "#each path in Paths is expressed as sequence of edge indexes\n",
    "\n",
    "def updateMaxMin(G,C,pathsEdges):\n",
    "    edges=list(G.edges())\n",
    "    \n",
    "    distinctEdgeIndexes=[]\n",
    "    for path in pathsEdges:\n",
    "        distinctEdgeIndexes+=list(path)\n",
    "    distinctEdgeIndexes=list(set(distinctEdgeIndexes))    \n",
    "    #calculate the maxMin allocation\n",
    "    maxMinAlloc=max_min_allocation(C,pathsEdges)\n",
    "    \n",
    "    #update the 'CurrentRate' attribute on affected nodes\n",
    "    for e in distinctEdgeIndexes:\n",
    "        G[edges[e][0]][edges[e][1]]['CurrentRate']=0.\n",
    "    for i in range(len(pathsEdges)):\n",
    "        path=pathsEdges[i]\n",
    "        for p in path:\n",
    "            G[edges[p][0]][edges[p][1]]['CurrentRate']+=maxMinAlloc[i]\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a path expressed as nodes, it returns a path expressed as \n",
    "#sequence of INDEXES of links traversed, the list of links being linksList.\n",
    "def nodesToLinksIndexes(pathNodes,linksList):\n",
    "    path=[]\n",
    "    f=0\n",
    "    for i in range(len(pathNodes)-1):\n",
    "        a=pathNodes[i]\n",
    "        b=pathNodes[i+1]\n",
    "        for k in range(len(linksList)):\n",
    "            if linksList[k,0]==a and linksList[k,1]==b:\n",
    "                f=1\n",
    "                break\n",
    "        if f:\n",
    "            path.append(k)\n",
    "        else:\n",
    "            raise ValueError('invalid path: link from node'+str(a)+' to node '+str(b)+' does not exist')            \n",
    "    return np.array(path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the graph\n",
    "K=8 #number of pods\n",
    "G=nx.DiGraph()#initialize the graph\n",
    "fatTree=getFatTree(K)#calculate fat tree topology \n",
    "links=fatTree[0] \n",
    "servers=fatTree[1]\n",
    "#input structure into the graph\n",
    "for l in links:\n",
    "    G.add_edge(l[0],l[1])\n",
    "    G[l[0]][l[1]]['CurrentRate']=0.\n",
    "    G[l[0]][l[1]]['Capacity']=10.\n",
    "    \n",
    "#store edges, nodes and capacities in np.arrays for easier use in the following\n",
    "edges=np.array(G.edges())\n",
    "nodes=np.array(G.nodes())\n",
    "C=10*np.ones(len(edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for K in [8,32,64]: #number of pods\n",
    "    G=nx.DiGraph()#initialize the graph\n",
    "    fatTree=getFatTree(K)#calculate fat tree topology \n",
    "    links=fatTree[0] \n",
    "    servers=fatTree[1]\n",
    "    #input structure into the graph\n",
    "    for l in links:\n",
    "        G.add_edge(l[0],l[1])\n",
    "        G[l[0]][l[1]]['CurrentRate']=0.\n",
    "        G[l[0]][l[1]]['Capacity']=10.\n",
    "\n",
    "    #store edges, nodes and capacities in np.arrays for easier use in the following\n",
    "    edges=np.array(G.edges())\n",
    "    nodes=np.array(G.nodes())\n",
    "    C=10*np.ones(len(edges))\n",
    "\n",
    "    P=getAllECMPs_parallel(G,servers,4)\n",
    "    with open('../../../allShortestPathsK'+str(K)+'.pkl','wb') as f:\n",
    "        pickle.dump(ECMPs,f,pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths as generated by ECMP (sequence of nodes)\n",
    "pathNodes=[ECMP(G,nodes[i],nodes[1023-i]) for i in range(1000)]\n",
    "#path transalted into links indexes\n",
    "pathEdges=[nodesToLinksIndexes(p,edges) for p in pathNodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#update edges usage\n",
    "G=updateMaxMin(G,C,pathEdges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "#check it is the same as the one produced in matlab\n",
    "K=16\n",
    "f=open('../matlab/fat_tree-connections.txt','r')\n",
    "ll=[]\n",
    "for l in f:\n",
    "    ll.append([int(x) for x in l[:-1].split(',')[:2]])\n",
    "ll=np.array(ll)\n",
    "LL=getFatTree(K)\n",
    "print np.max(LL[0]-ll),np.min(LL[0]-ll) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
